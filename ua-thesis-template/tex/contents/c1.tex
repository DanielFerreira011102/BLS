\chapter{Introduction}
\label{c1}

In recent years, there has been a growing demand for accessible and reliable health information online.
Consumers increasingly turn to the internet to find answers to their health-related questions, seeking guidance on topics like symptoms, treatments, and preventive care.
However, the complexity of medical information can be a significant barrier for many people.
Most health content is written for a highly educated audience, using technical jargon and assuming a high level of background knowledge \cite{clarke2016readability,storm2020assessing}.
This can lead to confusion, misunderstanding, and potentially even harmful decisions if people are unable to fully grasp the information they find \cite{charow2019readability}.
At the same time, oversimplifying medical information comes with its own risks.
Leaving out important details or nuance for the sake of simplicity can also lead to misinterpretation and poor decision-making \cite{clark2011simplifying}.
The ideal scenario would be to provide health information at a level of complexity tailored to each individual user's needs and background.
Someone with medical training should be able to access detailed, technical explanations, while someone with less health literacy should be able to find clear, straightforward answers that they can easily understand and act upon.
Artificial intelligence, particularly large language models (LLMs), have the potential to bridge this gap by dynamically generating health content at different complexity levels.
LLMs like GPT-3 \cite{brown2020languagemodelsfewshotlearners} and PaLM \cite{chowdhery2022palm} have demonstrated remarkable abilities to produce fluent, coherent text in a variety of domains.
By providing these models with health-related prompts, it may be possible to generate accurate, relevant answers to consumer health questions.
However, current LLMs lack fine-grained control over the complexity of their generated text.
While they can be prompted to give "simple" or "detailed" answers, there is no guarantee that the outputs will genuinely meet a specific target level of complexity.
For health applications in particular, it is critical to have robust, reliable control over the complexity of the generated text.
We need to ensure that "simple" answers are not \textit{too} simple, leaving out key information, and that "complex" answers do not introduce errors in an attempt to include more advanced terminology and concepts.
Therefore, the core motivation of this work is to develop a system that combines the flexibility and power of LLMs with the careful control needed for providing accurate, appropriate health information to a diverse public audience.
By enabling fine-grained control over the complexity of generated text, we aim to make health information more accessible and useful for everyone who needs it.

\begin{itemize}
\item Investigating existing approaches to controlled text generation and identifying their limitations in achieving fine-grained complexity control and maintaining semantic consistency.
\item Developing a novel controlled text generation approach that incorporates a continuous complexity control mechanism into a unified language model architecture.
\item Evaluating the proposed approach on various text generation tasks, assessing both the linguistic quality and the appropriateness of the generated text for different target audiences.
\item Exploring potential applications of the proposed approach in real-world scenarios, such as patient education materials, medical chatbots, and health information websites.
\end{itemize}