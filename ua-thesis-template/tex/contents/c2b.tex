\chapter{Background}
\label{c2}

This chapter presents the foundational concepts and current research in controlled text generation. We begin with an overview of large language models and their text generation capabilities, followed by a detailed examination of controlled text generation methods. The chapter concludes with an analysis of language complexity measurement approaches, which are essential for evaluating text simplification systems.

\section{Language Models}
\label{c2:s:language-models}

Language models are statistical models that learn to predict the probability distribution of words or tokens in a sequence. Modern neural language models, particularly those based on the Transformer architecture, process text through multiple layers of self-attention mechanisms that capture relationships between words at different positions in the sequence.

The text generation process in these models follows an autoregressive approach, where each token is predicted based on previously generated tokens. Given a sequence of tokens $X = \{x_1, x_2, ..., x_n\}$, the model computes the probability of the next token as:

\begin{equation}
    P(X) = P(x_1, x_2, ..., x_n) = \prod_{i=1}^n p(x_i|x_{<i})
\end{equation}

where $x_{<i}$ represents all tokens before position $i$. This formulation allows the model to generate text by iteratively sampling tokens from the predicted probability distribution.

Pre-trained language models learn these probability distributions through self-supervised training on large text corpora. During pre-training, models can acquire various types of knowledge:

\begin{itemize}
    \item Syntactic patterns and grammatical rules
    \item Semantic relationships between words
    \item Domain-specific terminology and conventions
    \item Common facts and world knowledge
\end{itemize}

However, the standard generation process provides limited control over the attributes of the generated text. The model generates tokens based solely on learned probabilities, making it difficult to ensure specific characteristics in the output, such as maintaining a consistent style, following a particular format, or adhering to domain-specific constraints.

\section{Controlled Text Generation}
\label{c2:s:controlled-text-generation}

Controlled text generation addresses the challenge of guiding language models to produce text with specific desired properties while maintaining fluency and coherence \cite{liang2024controllabletextgenerationlarge, 10.1145/3617680, keskar2019ctrlconditionaltransformerlanguage, dathathri2020plugplaylanguagemodels}. Unlike standard text generation, controlled generation explicitly incorporates additional constraints or conditions into the generation process.

The task involves generating text that satisfies specified control conditions $C$ while preserving the quality of the original language model output. When we incorporate these control conditions into the generation process, the probability distribution becomes:

\begin{equation}
    P(X|C) = P(x_1, x_2, ..., x_n|C) = \prod_{i=1}^n p(x_i|x_{<i}, C)
\end{equation}

Control conditions $C$ can represent any definable text property and take various forms depending on the specific task requirements and application domain.

\subsection{Control Conditions and Types}

Control conditions in text generation serve different purposes based on the application requirements. These conditions broadly fall into three categories: semantic control, structural control, and lexical control.

\subsubsection{Semantic Control}

Semantic control focuses on abstract properties of the generated text:

\begin{itemize}
   \item \textbf{Safety:} Text generation systems must avoid producing harmful, toxic, or biased content. This includes detecting and preventing discriminatory language, hate speech, or misleading information. For example, when generating dialogue responses, the system should avoid suggesting harmful actions or expressing biased views.
   
   \item \textbf{Sentiment:} Applications often need to control the emotional tone of generated text. A customer service chatbot might need to maintain a positive tone, while a news article generator should maintain neutral sentiment. The sentiment control extends beyond simple positive/negative classification to include fine-grained emotional states.
   
   \item \textbf{Topic:} Topic control ensures the generated text remains focused on specific subject matter. For instance, when generating scientific text, the system should maintain relevant terminology and concepts while avoiding unrelated topics. Topic control becomes particularly important in long-form text generation where maintaining thematic coherence is crucial.
\end{itemize}

\subsubsection{Structural Control}

Structural control manages the organization and format of generated text:

\begin{itemize}
   \item \textbf{Format Specifications:} Many applications require text to follow specific formats. This includes generating poetry with particular rhyme schemes and meter, creating structured documents like academic papers or technical reports, or producing code with specific syntax requirements. The system must understand and maintain these format constraints throughout the generation process.
   
   \item \textbf{Document Organization:} Long-form text often requires specific organizational structures. This includes section ordering, paragraph breaks, and hierarchical relationships between different parts of the text. For example, a scientific paper generator needs to maintain standard sections like introduction, methods, results, and discussion.
   
   \item \textbf{Length Control:} Applications may need to generate text of specific lengths, from concise summaries to detailed explanations. Length control involves more than simple truncation - it requires generating complete, coherent text that naturally fits within the specified length constraints.
\end{itemize}

\subsubsection{Lexical Control}

Lexical control operates at the vocabulary level:

\begin{itemize}
   \item \textbf{Keyword Inclusion:} Some applications require the generated text to incorporate specific keywords or phrases. This is common in search engine optimization, technical documentation, or domain-specific content generation. The challenge lies in naturally integrating these keywords while maintaining text fluency.
   
   \item \textbf{Vocabulary Constraints:} Text generation systems often need to restrict their vocabulary based on the target audience or domain. For example, text simplification systems must avoid complex terminology when generating content for general audiences. Similarly, technical writing might require using standardized terminology from a controlled vocabulary.
   
   \item \textbf{Term Consistency:} In technical or specialized writing, maintaining consistent terminology throughout the text is crucial. This includes using the same terms for specific concepts and avoiding synonyms that might cause confusion.
\end{itemize}

\subsection{Challenges in Control Integration}

Integrating control conditions into text generation presents several technical challenges:

\begin{itemize}
   \item \textbf{Control-Quality Trade-off:} Stronger control over text attributes often comes at the cost of reduced fluency or naturalness. Finding the right balance between control strength and text quality remains an ongoing challenge.
   
   \item \textbf{Multiple Constraint Interaction:} When multiple control conditions are applied simultaneously, they may conflict with each other. For example, maintaining a specific sentiment while including required keywords, or following a strict format while ensuring topic relevance.
   
   \item \textbf{Long-range Consistency:} As text length increases, maintaining consistent control becomes more difficult. Models may drift from the specified attributes or lose coherence over longer sequences.
   
   \item \textbf{Implicit Control Factors:} Some control aspects, like style or tone, are difficult to specify explicitly and may depend on subtle linguistic features that are hard to capture and manipulate.
\end{itemize}

\subsection{Methods Overview}

Methods for implementing controlled text generation can be divided into two main approaches: training-time methods and inference-time methods. 
This division reflects when control mechanisms are integrated into the text generation process \cite{liang2024controllabletextgenerationlarge, he-etal-2022-ctrlsum}.

\begin{itemize}
   \item \textbf{Training-time Methods:} These methods modify the language model during the training phase through various techniques:
        \begin{itemize}
            \item Complete model retraining with control-specific objectives
            \item Fine-tuning to adapt existing models
            \item Training additional modules or adapters
            \item Reinforcement learning with feedback signals
        \end{itemize}
       
   \item \textbf{Inference-time Methods:} These methods guide text generation during inference without modifying the base model:
       \begin{itemize}
            \item Prompt design and engineering
            \item Guided decoding strategies
            \item Latent state manipulation
            \item Post-generation editing 
        \end{itemize}
\end{itemize}

\section{Training-time Methods}
\label{c2:s:training-time}

Training-time methods directly incorporate control mechanisms into the model's parameters or architecture. These methods aim to teach the model to recognize and respond to control signals during the training process.

\subsection{Model Retraining}

Complete model retraining is one of the earliest approaches to controlled text generation.
This method involves training a language model from scratch with control-specific architectures or objectives.

The CTRL model \cite{keskar2019ctrlconditionaltransformerlanguage} exemplifies this approach, introducing control codes to guide text generation. During training, each text segment in the dataset is paired with a control code that specifies attributes like style, domain, or topic. For example:

\begin{verbatim}
[Science] The study found significant correlations...
[Reviews Rating: 5.0] This product exceeded my expectations...
[Wikipedia] The Industrial Revolution began...
\end{verbatim}

CTRL learns to associate these codes with specific text characteristics through natural co-occurrence during training. 
The model processes control codes as special tokens that influence the entire generation process. 
The training data preparation involves:

\begin{itemize}
   \item Identifying relevant control attributes
   \item Creating consistent control code formats
   \item Collecting and labeling large-scale training data
   \item Ensuring balanced representation of different control codes
\end{itemize}

While CTRL demonstrates effective high-level control, the model cannot easily adapt to new control attributes without retraining, and the discrete nature of control codes limits the level of precision it can achieve.

The CoCon architecture \cite{chan2022coconselfsupervisedapproachcontrolled} addresses these limitations by introducing a more flexible content-conditioning mechanism. 
Instead of relying on discrete control codes, CoCon embeds control signals directly into the model's hidden states. 
The architecture combines a base language model with a dedicated content-conditioning module that processes control signals. 
Integration layers then combine the conditioned and base representations to influence the generation process.

To train this architecture effectively, CoCon implements multiple complementary loss functions:

\begin{itemize}
   \item \textbf{Primary Reconstruction Loss ($\mathcal{L}_{recon}$):} Ensures the model can accurately generate text that incorporates the given control signals
   \item \textbf{Null Content Loss ($\mathcal{L}_{null}$):} Helps the model maintain robust performance even when control signals are absent, which is important for practical applications
   \item \textbf{Cycle Reconstruction Loss ($\mathcal{L}_{cycle}$):} Promotes consistency in how control signals are applied. It ensures that if we extract control signals from a generated text and use them to condition another generation, we obtain similar results.
   \item \textbf{Adversarial Loss ($\mathcal{L}_{adv}$):} Improves the naturalness of the generated text by training the model to produce outputs that are indistinguishable from human-written text while maintaining the desired control attributes
\end{itemize}

The total loss function for training the CoCon model is a weighted combination of these four components:

\begin{equation}
    \mathcal{L}_{total} = \mathcal{L}_{recon} + \lambda_1 \mathcal{L}_{null} + \lambda_2 \mathcal{L}_{cycle} + \lambda_3 \mathcal{L}_{adv}
\end{equation}

where the $\lambda$ parameters balance the contribution of each loss term.

This multi-loss training strategy ensures that the model learns to balance control requirements with text fluency and coherence.
Furthermore, by keeping the original language model intact and only adding a lightweight content-conditioning module, CoCon largely preserves the pre-trained knowledge and capabilities of the base model.

For scenarios requiring precise lexical control, the POINTER model \cite{zhang-etal-2020-pointer} introduces a fundamentally different approach based on insertion-based generation. 
Unlike traditional left-to-right generation models that predict one token at a time in sequence, POINTER can insert tokens at any position in the sequence. 
This makes it particularly well-suited for ensuring specific keywords or phrases appear in the generated text.

POINTER operates through a progressive refinement process. 
The generation begins with an initial sequence containing only the required lexical constraints (i.e., the keywords or phrases that must appear in the final text). The model then iteratively inserts new tokens between existing ones, gradually building up the complete text. At each step, a learned policy determines both which tokens to insert and where to place them, considering the surrounding context and the overall coherence of the sequence.

This insertion-based approach provides several advantages for lexically constrained generation. It guarantees that required keywords will appear in the output since they form the starting point of generation. The ability to insert tokens at any position allows for more flexible text construction compared to strict left-to-right generation. However, this flexibility comes with computational costs, as each insertion operation requires evaluating multiple possible positions and tokens. The process can become particularly intensive for longer sequences where many insertions are needed to complete the text.

\subsection{Fine-tuning}

Fine-tuning adapts a pre-trained language model to handle controlled text generation by adjusting its parameters using specialized datasets or training objectives. 
This approach preserves the general language generation capabilities of the pre-trained model while improving its ability to respond to specific control signals.

The fine-tuning process modifies the model parameters according to:

\begin{equation}
    \Theta^* = \Theta + \Delta\Theta
\end{equation}

where $\Theta$ represents the original parameters of the pre-trained model, and $\Delta\Theta$ represents the updates learned during fine-tuning. The parameter updates are computed by minimizing a task-specific loss:

\begin{equation}
    \Delta\Theta = \arg\min_{\Theta} \mathcal{L}(D_{control}, f(X; \Theta))
\end{equation}

where $D_{control}$ is a dataset designed for the control task, and $f(X; \Theta)$ represents the model's output for input $X$.

\subsubsection{Adapter-Based Fine-tuning}

Adapter-based fine-tuning introduces specialized neural modules into the pre-trained model while keeping its original parameters frozen. This reduces the risk of catastrophic forgetting, where fine-tuning causes the model to lose previously learned knowledge.

Auxiliary Tuning \cite{zeldes2020technicalreportauxiliarytuning} adds a separate auxiliary model alongside the pre-trained language model. 
The auxiliary model processes both the input text and control signals, producing logits that are combined with the base model's output through a softmax operation:

\begin{equation}
    P(y|x,C) = \text{softmax}(f_{LM}(x) + f_{AUX}(x,C))
\end{equation}

where $f_{LM}$ represents the frozen pre-trained model and $f_{AUX}$ is the trainable auxiliary model. 
Intuitively, the auxiliary model learns the residual logits needed to shift the probability distribution of the pre-trained model towards the target distribution.
To further improve training efficiency, the lower layers of the pre-trained model can also be used as a feature extractor for the auxiliary model inputs. 
There are no constraints on the auxiliary model architecture, except that it must output logits over the same vocabulary as the original model.
It is typically much smaller than the pre-trained model (e.g., a few Transformer layers) and can be trained on a small amount of data.

DisCup \cite{zhang2022discupdiscriminatorcooperativeunlikelihood} combines discriminator guidance with prompt-tuning.
The training objective includes both likelihood and unlikelihood terms:

\begin{equation}
    \mathcal{L}_{total} = \sum_{i=1}^{|D|} \sum_{t=1}^{|x^{(i)}|} \mathcal{L}_{like}(x_t^{(i)}) + \mathcal{L}_{unlike}(x_t^{(i)})
\end{equation}

For each training step, the base model generates candidate tokens which the discriminator scores based on their alignment with desired attributes. 
$\mathcal{L}_{like}$ maximizes the probability of positively-scored tokens, while $\mathcal{L}_{unlike}$ minimizes the probability of negatively-scored ones. 
The unlikelihood training helps prevent the model from learning spurious correlations present in training data.
Furthermore, by operating on self-generated candidates rather than ground-truth tokens, DisCup maintains output diversity while improving attribute control.

LiFi \cite{shi2024lifilightweightcontrolledtext} proposes an efficient approach using lightweight adapters guided by attribute classifiers. The adapters are added to each transformer layer while keeping the base model frozen:

\begin{equation}
    h' = h + \text{Adapter}(h, c)
\end{equation}

where $h$ is the layer's hidden state and $c$ is the control signal from the classifier. The adapters use a bottleneck architecture with reduction factors of 16 and 4 for feedforward and attention modules respectively, adding only 0.04\% parameters to the base model.

During generation, multiple adapters can be combined through a weighted fusion mechanism:

\begin{equation}
    h'_t = h_t + \sum_{i=1}^k w_i \text{Adapter}_i(h_t, c_i)
\end{equation}

where $w_i$ are learnable weights balancing different control signals. This allows LiFi to handle multiple control attributes while maintaining computational efficiency.

\subsubsection{Data-Driven Fine-Tuning}

FLAN \cite{wei2022finetunedaszeroshotlearners} takes a different approach by converting control tasks into natural language instructions. Rather than adding model components, FLAN fine-tunes the language model to follow text instructions that specify desired attributes and constraints. This instruction-based approach enables zero-shot generalization to new control tasks that can be expressed through natural language prompts.

Instruction tuning improves further with InstructCTG \cite{zhou2023controllabletextgenerationnatural}, which builds specialized instruction datasets for controlled generation. The method converts various types of constraints into clear instructions:

\begin{verbatim}
Write a [positive] review about [topic]:
Generate text containing keywords [x, y, z]:
\end{verbatim}

This explicit instruction format helps the model learn generalizable control strategies that can be applied across different tasks and domains.