---
title: Simple or Complex? Complexity-controllable Question Generation with Soft Templates and Deep Mixture of Experts Model
authors: Sheng Bi, Xiya Cheng, Yuan-Fang Li, Lizhen Qu, Shirong Shen, Guilin Qi, Lu Pan, Yinlin Jiang
year: 2021
database: ACL Anthology
citekey: bi-etal-2021-simple-complex
tags:
  - ctg
url: https://aclanthology.org/2021.findings-emnlp.397/
file: "[[Simple or Complex - Complexity-Controllable Question Generation with Soft Templates and Deep Mixture of Experts Model.pdf]]"
---

>[!title]
Simple or Complex? Complexity-controllable Question Generation with Soft Templates and Deep Mixture of Experts Model

>[!year]
2021

>[!author]
Sheng Bi, Xiya Cheng, Yuan-Fang Li, Lizhen Qu, Shirong Shen, Guilin Qi, Lu Pan, Yinlin Jiang


------------------------------------

### Summary


------------------------------------

### Research question


------------------------------------

### Context


------------------------------------

### Methodology


------------------------------------

### Findings


------------------------------------

### Discussion


------------------------------------

### Remarks & Limitations


------------------------------------

### Citation

```
@inproceedings{bi-etal-2021-simple-complex,
    title = "Simple or Complex? Complexity-controllable Question Generation with Soft Templates and Deep Mixture of Experts Model",
    author = "Bi, Sheng  and
      Cheng, Xiya  and
      Li, Yuan-Fang  and
      Qu, Lizhen  and
      Shen, Shirong  and
      Qi, Guilin  and
      Pan, Lu  and
      Jiang, Yinlin",
    editor = "Moens, Marie-Francine  and
      Huang, Xuanjing  and
      Specia, Lucia  and
      Yih, Scott Wen-tau",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2021",
    month = nov,
    year = "2021",
    address = "Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.findings-emnlp.397",
    doi = "10.18653/v1/2021.findings-emnlp.397",
    pages = "4645--4654",
    abstract = "The ability to generate natural-language questions with controlled complexity levels is highly desirable as it further expands the applicability of question generation. In this paper, we propose an end-to-end neural complexity-controllable question generation model, which incorporates a mixture of experts (MoE) as the selector of soft templates to improve the accuracy of complexity control and the quality of generated questions. The soft templates capture question similarity while avoiding the expensive construction of actual templates. Our method introduces a novel, cross-domain complexity estimator to assess the complexity of a question, taking into account the passage, the question, the answer and their interactions. The experimental results on two benchmark QA datasets demonstrate that our QG model is superior to state-of-the-art methods in both automatic and manual evaluation. Moreover, our complexity estimator is significantly more accurate than the baselines in both in-domain and out-domain settings.",
}
```