In medicine, answering clinical questions at the level of trained physicians has long been seen as a "grand challenge." Today, there are multiple models capable of passing medical exams like the USMLE. However, most fall short of matching the depth, safety, and alignment of human-generated answers, especially in critical and nuanced real-world settings where the stakes are extraordinarily high.

[[@dathathri2020plugplaylanguagemodels]]
Dathathri et al. (2020) introduced Plug and Play Language Models (PPLM), which enable controlled text generation through gradient updates in a language model's latent space. The authors demonstrated that we can achieve control over topic and sentiment by combining GPT-2 with lightweight attribute controllers, either bag-of-words or simple discriminators. Since the optimization is done retroactively in the activation space, we wouldn't need to retrain or fine-tune our base model, saving us significant computing resources. The method also allows multiple controllers to work together and provides fine-grained control through a strength parameter $\alpha$ that can be tuned to achieve different levels of attribute control, even in challenging scenarios - exactly what we need for adjusting medical text complexity. 
The main issue with this approach is the lack of literature on its application to biomedical content, where factual accuracy is non-negotiable. Standard attribute controllers might fail to distinguish between subtle variations in medical language complexity, from simple explanations to technical details. The method's computational demands during inference could also limit its use in real-time medical QA systems.